{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ca7e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer \n",
    "# this is used as each row has different labels of the same category \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93f515f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the cleaned datasets and not the original one as we are using modular approach\n",
    "df=pd.read_csv('cleaned_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37997b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering i.e. encoding categorical to numerical\n",
    "\n",
    "print(df['Genre'].nunique()) # gives the number of unique genre strings from each row so its value is large as it checks the strings\n",
    "\n",
    "\n",
    "df['Genre_list']=df['Genre'].apply(lambda x: list(dict.fromkeys(i.strip() for i in x.split(','))))\n",
    "'''\n",
    "dict.fromkeys is used to remove the duplicates as in dictionary no 2 keys can be same\n",
    "and list () is used to convert this to list\n",
    "strip to remove any spaces \n",
    "this line just give me the list of the grenre across all the rows i.e. removes repetioon on the rows but not on whole datasets\n",
    "but multilabelbinarizer only makes columns of the unique list\n",
    "'''\n",
    "df['genre_count']=df['Genre_list'].apply(len)\n",
    "print(df['genre_count'])\n",
    "# multilabelizer for genre\n",
    "mlb_genre =MultiLabelBinarizer()\n",
    "Genre_encoded =pd.DataFrame(mlb_genre.fit_transform(df['Genre_list']), columns=mlb_genre.classes_)\n",
    "'''\n",
    "fit_transform() gives numpy arrays without any names or titles of columns so column name is given on the basis\n",
    "of the Genre_list stored at the mlb_genre.classes_\n",
    "The unique genres found in df['Genre_list']\n",
    "during fit_transform() are automatically saved into mlb_genre.classes_.\n",
    "'''\n",
    "df = pd.concat([df, Genre_encoded], axis=1)\n",
    "\n",
    "print(Genre_encoded.columns.duplicated().any())  # should be False\n",
    "\n",
    "print(Genre_encoded)\n",
    "print(mlb_genre.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45279908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now for the director \n",
    "\n",
    "# to stop memory fragmentation we do one hot encoding at once\n",
    "top=df['Director'].value_counts().nlargest(50).index.tolist() # n=100 and index gives the name/labels of the these directors\n",
    "direncode=pd.get_dummies(df['Director'])\n",
    "direncode=direncode[top]\n",
    "direncode=direncode.astype(int)\n",
    "\n",
    "print(df['Rating'])\n",
    "# target encoding for directors used over frequency to see which gives better results\n",
    "directorMean=df.groupby('Director')['Rating'].mean()\n",
    "df['directorTargetEnc']=df['Director'].map(directorMean)\n",
    "print(df['directorTargetEnc'])\n",
    "\n",
    "#  add  other column\n",
    "df['Director_other']=(~df['Director'].isin(top)).astype(int)\n",
    "\n",
    "# frequency encoding to get more numeric information\n",
    "fq=df['Director'].value_counts(normalize=True)\n",
    "df['Director_frequnency']=df['Director'].map(fq)\n",
    "\n",
    "# concatenating these 100 columns into the dataframe\n",
    "df=pd.concat([df,direncode],axis=1)\n",
    "\n",
    "# removing the duplicates as they were created running this loop version\n",
    "df = df.loc[:, ~df.columns.duplicated()]\n",
    "\n",
    "\n",
    "''' \n",
    "this finds thr top 100 most frequent directors \n",
    "it is a list of names of directors given as by .index\n",
    "\n",
    "# one hot encoding/ binary encoding\n",
    "for Director in top:\n",
    "    df[f'Director_{Director}']=(df['Director']==Director).astype(int)\n",
    "    this adds the columns in a loop 1 by 1 thus it is fragmented and inefficient \n",
    "    to make it efficient we need to add it at once\n",
    "    \n",
    "    '''\n",
    "\n",
    "print(df.columns[df.columns.duplicated()]) # this is to check if there are duplicates or not\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f899faaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now for actors \n",
    "# combinining actors 1 2 3 into single list column for each row\n",
    "df['actors']=df[['Actor 1','Actor 2','Actor 3']].values.tolist()\n",
    "\n",
    "# counting top 100s actors\n",
    "allActors= df['actors'].explode()  \n",
    "top= allActors.value_counts().nlargest(50).index\n",
    "'''\n",
    "explode is used to give all the actors names as in actors i.e. every row with repetition \n",
    "this is used to calulate the top actors\n",
    "'''\n",
    "\n",
    "# order insensitivity encoding\n",
    "\n",
    "df = df.loc[:, ~df.columns.duplicated()]\n",
    "\n",
    "# to remove the memory fragmentation problem create an empty dataframe to hold new columns\n",
    "dumies=pd.DataFrame(index=df.index)\n",
    "\n",
    "for actor in top:\n",
    "    dumies[f'actors_{actor}']=df['actors'].apply(lambda x: int(actor in x))\n",
    "\n",
    "# nor concatenate all columns at once to original df\n",
    "df=pd.concat([df,dumies],axis=1)\n",
    "    \n",
    "new_actor_cols = [col for col in df.columns if col.startswith('actors_')]\n",
    "\n",
    "\n",
    "print(len(new_actor_cols))  # How many columns?\n",
    "print(len(set(new_actor_cols)))  # Are there duplicates in names?\n",
    "\n",
    "print(df.columns.duplicated().sum())  # Should be 0 ideally\n",
    "actor_counts = df[new_actor_cols].sum().sort_values(ascending=False)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9ecc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sving the encoded one to the csv\n",
    "df.to_csv(\"cleaned_encoded.csv\", index= False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datavenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
